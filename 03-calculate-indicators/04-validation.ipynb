{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "\n",
    "# load configs\n",
    "with open('../config.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "indicators_path = config['indicators_path'] #indicators data\n",
    "graphml_folder = config['models_graphml_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many unsimplified node edges were there?\n",
    "\n",
    "Extract from logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the log from the download process\n",
    "with open('/data/wc/logs/osmnx_2020-04-29.log') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_count = 0\n",
    "edge_count = 0\n",
    "for line in lines:\n",
    "    if 'Created graph with' in line:\n",
    "        \n",
    "        n_start = line.find('with ') + 5\n",
    "        n_end = line.find(' nodes')\n",
    "        nodes = int(line[n_start:n_end].replace(',', ''))\n",
    "        node_count += nodes\n",
    "\n",
    "        m_start = line.find('and ') + 4\n",
    "        m_end = line.find(' edges')\n",
    "        edges = int(line[m_start:m_end].replace(',', ''))\n",
    "        edge_count += edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(node_count, edge_count)\n",
    "# prints 150944806 301110128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate networks elevations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(indicators_path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation btw mean node elevation and average UC elevation (EORC and JAXA)\n",
    "df[['elev_mean', 'avg_elevation']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = df['elev_mean'] - df['avg_elevation']\n",
    "diff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check intersection cleaning tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepaths(row):\n",
    "    country_folder = row['country'] + '-' + row['country_iso']\n",
    "    filename = row['core_city'] + '-' + str(row['uc_id'])\n",
    "    filepath = os.path.join(graphml_folder, country_folder, filename) + '.graphml'\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_intersections(filepath, save_graph=True):\n",
    "    # load the network\n",
    "    tolerance = 10\n",
    "    G = ox.load_graphml(filepath)\n",
    "    G_proj = ox.project_graph(G)\n",
    "\n",
    "    # get the clean intersections\n",
    "    intersections_clean = ox.clean_intersections(G_proj,\n",
    "                                                 tolerance=tolerance,\n",
    "                                                 dead_ends=False)\n",
    "    intersections_clean.name = 'geometry'\n",
    "    intersections_clean = gpd.GeoDataFrame(intersections_clean, crs=G_proj.graph['crs'])\n",
    "    intersections_clean_latlng = ox.project_gdf(intersections_clean, to_latlong=True)\n",
    "\n",
    "    # get all intersections (ie non dead-end nodes)\n",
    "    node_ids = set(G.nodes())\n",
    "    intersections = [node for node, count in G.graph['streets_per_node'].items() if (count > 1) and (node in node_ids)]\n",
    "    gdf_nodes = ox.graph_to_gdfs(G, edges=False, node_geometry=True)\n",
    "    intersections = gdf_nodes.loc[intersections]\n",
    "    \n",
    "    # save graph, intersections, and clean intersections GPKGs to disk\n",
    "    filename = filepath[filepath.rfind('/')+1:-8]\n",
    "    intersections.to_file(f'/home/geoff/Desktop/{filename}-ints.gpkg', driver='GPKG')\n",
    "    intersections_clean.to_file(f'/home/geoff/Desktop/{filename}-ints-clean.gpkg', driver='GPKG')\n",
    "    \n",
    "    if save_graph:\n",
    "        ox.save_graph_geopackage(G, filename=f'{filename}-graph.gpkg', folder='/home/geoff/Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = df['intersect_count_clean'] / df['intersect_count']\n",
    "df['ratio'] = ratio\n",
    "ratio.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('length_mean')[['country', 'core_city', 'uc_id', 'intersect_count', 'ratio', 'length_mean']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below saves each of these networks, their intersections, and their clean intersections to desktop to visually inspect in QGIS. All are examples of code intersection cleaning to get better count/density indicators, except for Kismayo which does not work well because tiny footpaths in a slum are digitized as residential roads on OSM, so they are very dense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine grain networks\n",
    "cols = ['world_region', 'country', 'core_city', 'uc_id', 'area', 'n', 'intersect_count', 'intersect_count_clean', 'ratio']\n",
    "idx = ratio.sort_values().index\n",
    "x = df.loc[idx, cols].head(200)\n",
    "#x = df[df['world_region'].isin(['Europe', 'Northern America'])]\n",
    "uc_ids = [883, 706, 1027, 2234, 10241, 5572]\n",
    "x = df[df['uc_id'].isin(uc_ids)][cols]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = x.index\n",
    "filepaths = df.loc[idx].apply(get_filepaths, axis='columns').to_list()\n",
    "for filepath in filepaths:\n",
    "    save_intersections(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coarse grain networks: PHX, Buenos Aires\n",
    "uc_ids = [79, 1105]\n",
    "x = df[df['uc_id'].isin(uc_ids)][cols]\n",
    "idx = x.index\n",
    "filepaths = df.loc[idx].apply(get_filepaths, axis='columns').to_list()\n",
    "for filepath in filepaths:\n",
    "    save_intersections(filepath, save_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ox)",
   "language": "python",
   "name": "ox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
